---
title: "Arrests 2010 NTA: Analisi"
output:
  bookdown::pdf_document2:
    number_sections: false
    fig_caption: true
    lang: italian
lang: italian
header-includes:
- \usepackage{float}
---


# Analisi NTA 2010 - 2011 interazione tra variabili

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.align = 'center')

library(bookdown)
```

```{r, message=FALSE, warning=FALSE, results='hide'}
rm(list = ls())
gc(verbose = FALSE)
library(gridExtra)
library(sf)
library(ggplot2)

# plotting parameters 1d plot
OUT.WIDTH.1d = "60%"
OUT.HEIGHT.1d = "60%"

# plotting parameters 2d plots
OUT.WIDTH = "45%"
OUT.HEIGHT = "60%"

source("functions_script.R")
```

```{r}
# Condition: if TRUE execute the computational heavy chunks, else not
# assuming the models are been loaded from a RData file before.
# IMPORTANT: in order to reproduce the result set bool_execute_heavy_chunks = TRUE

bool_execute_heavy_chunks = FALSE
file_save_name = "rdata/arrests_nta_2010_models_summary.Rdata"
load(file_save_name)

file_joined_zero_counts_2010_df = "rdata/joined_zero_counts_2010.Rdata"
load(file_joined_zero_counts_2010_df)

month.cv.k4.sets.name = "rdata/month_cv_set_name.RData"
month.zeros.cv.k4.sets.name = "rdata/month_zeros_cv_set_name.RData"

load(month.cv.k4.sets.name)
load(month.zeros.cv.k4.sets.name)

# best models fitted on all data
# estimated_best_models = TRUE
# models_fitted_file_name = "models_fitted_nta_2010.Rdata"
# 
# # require loading models_summary list
# if(!estimated_best_models){
#   load(models_fitted_file_name)
# } else{
#   # store each model useful information:
#   # validation error and beta for best lambda
#   models_fitted_file_name = list()
# }
```


```{r}
# Preprocessing -------------------------------------
# read the data
df_2010 = read.csv("../../data/final_datasets/arrests_2010_nta.csv", stringsAsFactors = T)

# test set
df_2011 = read.csv("../../data/final_datasets/arrests_2011_nta.csv", stringsAsFactors = T)
```

```{r, message=FALSE, results='hide'}
df_2010$ARREST_DATE = NULL
df_2010$YEAR = NULL
df_2010$Latitude = NULL
df_2010$Longitude = NULL

df_2010$NTA2020 = factor(df_2010$NTA2020)
df_2010$MONTH = factor(df_2010$MONTH)

# add NA category
df_2010$KY_CD = ifelse(is.na(df_2010$KY_CD), "MISSING", df_2010$KY_CD)
df_2010$KY_CD = factor(df_2010$KY_CD)

str(df_2010)

# check for NA
apply(df_2010, 2, function(col) (sum(is.na(col))))

# the ratio is high
nrow(na.omit(df_2010)) / nrow(df_2010)

# delete missing values
df_2010 = na.omit(df_2010)


df_2011$ARREST_DATE = NULL
df_2011$YEAR = NULL
df_2011$Latitude = NULL
df_2011$Longitude = NULL

df_2011$NTA2020 = factor(df_2011$NTA2020)
df_2011$MONTH = NULL

# add NA category
df_2011$KY_CD = ifelse(is.na(df_2011$KY_CD), "MISSING", df_2011$KY_CD)
df_2011$KY_CD = factor(df_2011$KY_CD)

str(df_2011)

# check for NA
apply(df_2011, 2, function(col) (sum(is.na(col))))

# the ratio is high
nrow(na.omit(df_2011)) / nrow(df_2011)

# delete missing values
df_2011 = na.omit(df_2011)
```


## Descrizione

L'obbiettivo di questa sezione di analisi è verificare se esiste un sottoinsieme di variabili esplicative particolarmente correlate con il numero di arresti, sia marginalmente che considerando l'interazione con ciascuna zona spaziale (NTA).
Per vincoli computazionali si riduce l'insieme di stima al solo anno 2010: per quest'anno i dati del censo sono esatti e non si sono verificati eventi rari a differenza del 2020 (Covid); l'insieme di verifica scelto è l'anno 2011, in quanto è l'anno più vicino al 2010 (l'assunzione è che i due anni siano abbastanza simili per il fenomeno considerato).

### Problematiche

Questi dati presentano diverse problematiche.

Le scelte fatte sono dovute a fattori computazionali, di tempo e al fatto che per permettere conteggi diversi da 1 è necessario considerare zone spaziali e intervalli temporali non eccessivamente ristretti.

Per quanto concerne gli intervalli temporali si è scelto di ignorare i possibili trend e considerare i singoli anni, per ciascun anno si sono utilizzati i mesi per la costruzione degli insiemi di convalida incrociata. Pur avendo a disposizione il giorno di ciascun arresto la selezione dei mesi è apparsa come un giusto compromesso per garantire che non tutti i conteggi fossero uguali a 1 che comunque è il conteggio minino e più frequente molto superiore a tutti gli altri conteggi:

```{r}

df_2010_grouped = suppressMessages(df_2010 %>%
  dplyr::select(-MONTH) %>% 
  group_by_all() %>% 
  summarise(count = n()))

df_2011_grouped = suppressMessages(df_2011 %>%
  group_by_all() %>% 
  summarise(count = n()))

```

```{r count-arrests, fig.show='hold', out.width = OUT.WIDTH.1d, out.height= OUT.HEIGHT.1d,fig.cap="Tabella di frequenza assoluta per il numero di arresti raggruppando i dati del 2010 per tutte le variabili ad eccezione dei mesi"}
df_2010_grouped$count %>%
  table %>% 
  barplot(main = "Arrests count 2010 (grouping by covariates)",
       xlab = "number of arrests",
       ylab = "absolute frequency")
```


Questa "sovradispersione" di 1 è ragionevole data la costruzione dei conteggi per aggregazione di osservazioni con le stesse combinazioni di covariate; si dovrebbero inoltre aggiungere osservazioni con conteggi nulli per ogni combinazione di variabili per cui non si sono osservati arresti.

Mantenere tutti i conteggi unitari rende computazionalmente molto oneroso l'addattamenteo dei modelli e può creare problemi nella selezione degli stessi 

La soluzione adottata è basata sul sottocampionamento: si stabilisce una soglia per i valori di conteggi oltre cui non sottocampionare, si conta la frequenza di conteggi osservati per tale soglia e si sottocampiona un sottoinsieme di grandezza uguale a quella frequenza da ciascun sottoinsieme di conteggi con valori inferiori alla soglia.

L'assunzione di fondo è che, almeno per i conteggi fino alla soglia considerata, la frequenza sia descrescente rispetto al valore degli stessi; un aspetto da sottolineare della metodologia proposta, in quanto compromesso, è che introduce distorsione nelle stime.

Si considerano due tipologie di dataset, entrambi impiegano il sottocampiomamento, ma in uno i conteggi nulli sono presenti e nell'altro sono assenti (i modelli per risposta continua sono adattati impiegando una trasformazione logaritmica dei dati senza conteggi nulli).

Per questo studio la soglia selezionata che è apparsa ragionevole in base alle considerazioni precedenti è di conteggi uguali a 10.

Il sottocampionamento è effettuato anche per i dataset completi relativi a 2010 e 2011 (escludendo i mesi come variabile di raggruppamento), ma non sono stati aggiunti gli zeri per permettere il confronto tra modelli per risposta continua.


```{r, eval = bool_execute_heavy_chunks, results='hide'}

set.seed(123)

# make a zero count dataframe for each unseen combination of variable values in the original data.
library(hash)

set.seed(123)

# Save NTA stratification info
nta_strat_df <- df_2010 %>% 
  dplyr::select(-c(KY_CD, AGE_GROUP, PERP_RACE, PERP_SEX, LAW_CAT_CD, MONTH)) %>% 
  unique()

df_2010_no_strat <- df_2010 %>% 
  dplyr::select(-c(Pop1, MdAge, MaleP, Hsp1P, BNHP, OthNHP, WNHP, ANHP, MIncome))

# Number of zero count observations added to each month multiplied by the number of months
Z <- 5 * 10^3

# Initialize the zero counts data frame
zero_counts_2010_df <- as.data.frame(matrix(NA, nrow = Z * 12, ncol = ncol(df_2010_no_strat)))
colnames(zero_counts_2010_df) <- colnames(df_2010_no_strat)

# Get unique values for each column
unique_vals <- apply(df_2010_no_strat, 2, unique)

# Create a hash set to store existing combinations
existing_combinations <- hash()

# Add existing combinations to the hash set
for (i in 1:nrow(df_2010_no_strat)) {
  key <- paste(df_2010_no_strat[i, ], collapse = "_")
  existing_combinations[[key]] <- TRUE
}

# Generate zero counts for each month
for (month in 1:12) {
  for (i in 1:Z) {
    cond <- TRUE
    
    while (cond) {
      proposal <- sapply(unique_vals, function(el) sample(el, 1))
      proposal["MONTH"] <- factor(month, levels = 1:12)
      key <- paste(proposal, collapse = "_")
      
      if (!has.key(key, existing_combinations)) {
        zero_counts_2010_df[(month - 1) * Z + i, ] <- proposal
        existing_combinations[[key]] <- TRUE
        cond <- FALSE
      }
    }
  }
}

# Join with NTA stratification info
joined_zero_counts_2010_df <- left_join(zero_counts_2010_df, nta_strat_df, by = "NTA2020")


# Clean up
rm(df_2010_no_strat)
rm(zero_counts_2010_df)
gc()

# Add count column
joined_zero_counts_2010_df$count <- 0

joined_zero_counts_2010_df = joined_zero_counts_2010_df %>% mutate(across(where(is.character), as.factor))

# strat_cols <- c("KY_CD", "AGE_GROUP", "PERP_RACE", "PERP_SEX", "LAW_CAT_CD", "MONTH")
# exclude_cols <- c("Pop1", "MdAge", "MaleP", "Hsp1P", "BNHP", "OthNHP", "WNHP", "ANHP", "MIncome")



save(joined_zero_counts_2010_df, file = file_joined_zero_counts_2010_df)

```


### Elevata dimensionalità

I dati presentano elevata dimensionalità considerando le interazioni tra la variabile spaziale (NTA) e le covariate (qualitative) di arrests.
E' comunque interessante provare i metodi di selezione delle variabili anche sui dati senza interazioni.

Per avere delle misure quantitative si considera il dataset in cui si sono definiti i conteggi senza considerare i mesi: si riporta il rapporto tra il numero di osservazioni (righe) e il prodotto tra il numero di modalità di NTA e la somma delle modalità delle variabili qualitative di arrests.

```{r}
set.seed(123)

df_2010_grouped_subsampled = Subsample_Below_Threshold(df = df_2010_grouped, threshold = 10)
df_2011_grouped_subsampled = Subsample_Below_Threshold(df = df_2011_grouped, threshold = 10)
```


```{r}
var_unique_len = apply(df_2010_grouped_subsampled,
                       2,
                       function(col) length(unique(col)))
```

Senza considerare interazioni tra KY_CD (esplicativa non spaziale di arrest con più modalità) con gli NTA il rapporto è (considerando i dati 2011 :
```{r, include = TRUE}
nrow(df_2010_grouped_subsampled) / (var_unique_len["NTA2020"] *
  sum(var_unique_len[c("LAW_CAT_CD", "AGE_GROUP", "PERP_SEX", "PERP_RACE")]))
```

Considerando anche interazioni tra KY_CD e NTA rapporto è:
```{r, include=TRUE}
nrow(df_2010_grouped_subsampled) / (var_unique_len["NTA2020"] *
  sum(var_unique_len[c("KY_CD", "LAW_CAT_CD", "AGE_GROUP",
                       "PERP_SEX", "PERP_RACE")]))
```


## Modelli

### Criterio di selezione dei parametri di regolazione

Come già accennato, i parametri di regolazione sono selezionati tramite convalida incrociata (CV) impiegando i mesi per la costruzione degli insiemi.

La procedura per la costruzione degli insiemi è la seguente:
- Selezione di k: il numero di insiemi di convalida (ad esempio k = 4)
- Ogni insieme di convalida è composto da osservazioni raggruppate di 12 / k (3) mesi e i mesi rimanenti (9) vengono utilizzati per adattare il modello.
- Per cercare di compensare e mediare le fluttuazioni stagionali, i mesi di validazione sono scelti il più distanziati possibile. Ad esempio, nel caso di k = 4, il primo insieme di validazione è (gennaio, maggio, settembre), il secondo set è (febbraio, giugno, ottobre), il terzo è (marzo, luglio, novembre) e il quarto è (aprile, agosto, dicembre).
- Per rendere ogni risposta comparabile avendo utilizzato un numero diverso di mesi, una nuova risposta è definita come il rapporto degli arresti diviso per il numero di mesi utilizzati nel raggruppamento (ovvero l'esponenziale dell 'offset nel modello di Poisson).


```{r}
# months indexes sets
# each list contains a matrix where each row contains the used indexes
month_sets_ind = list(k4 = matrix(c(1, 5, 9,
                                    2, 6, 10,
                                    3, 7, 11,
                                    4, 8, 12),
                                  byrow = T,
                                  nrow = 4),
                      
                      k6 = matrix(c(1, 7,
                                    2, 8,
                                    3, 9,
                                    4, 10,
                                    5, 11,
                                    6, 12),
                                  byrow = T,
                                  nrow = 6))
```

### Matrice del modello

La matrice del modello considerata è quella con tutte le variabili e le interazioni tra tutte le variabili di arrests tranne KY_CD (per ragioni computazionali) e le zone spaziali degli NTA.
```{r, include=TRUE}


FORMULA.YES.INTERACTIONS = as.formula("count ~. -1 +
                            NTA2020:LAW_CAT_CD + 
                            NTA2020:AGE_GROUP + 
                            NTA2020:PERP_SEX + 
                            NTA2020:PERP_RACE")
```


```{r}
# if count is the response variable and count = 0
# the sparse matrix deletes the row...

FORMULA.YES.INTERACTIONS.sparse = as.formula("temp_response ~. -1 - count +
                            NTA2020:LAW_CAT_CD + 
                            NTA2020:AGE_GROUP + 
                            NTA2020:PERP_SEX + 
                            NTA2020:PERP_RACE")
```


```{r, warning=FALSE, results='hide'}

df_2010_grouped_subsampled.matrix = sparse.model.matrix(FORMULA.YES.INTERACTIONS,
                                                df_2010_grouped_subsampled)

df_2011_grouped_subsampled.matrix = sparse.model.matrix(FORMULA.YES.INTERACTIONS,
                                                df_2011_grouped_subsampled)
gc()
```


Poichè la matrice del modello dell'insieme di verifica e quella dell'insieme di stima non condividono tutte le colonne si considerare solo le colonne in comune alle due.
```{r}


# check dimensions
dim(df_2010_grouped_subsampled.matrix)
dim(df_2011_grouped_subsampled.matrix)

col_names_2010 = colnames(df_2010_grouped_subsampled.matrix)
col_names_2011 = colnames(df_2011_grouped_subsampled.matrix)

common_col_names = intersect(col_names_2010, col_names_2011)

# in order to use 2011 as a test set we need to uniform the 2011 columns to 2010 colums:
# some bias is introduced here, let's hope it's about small counts
df_2010_grouped_subsampled.matrix = df_2010_grouped_subsampled.matrix[,common_col_names]
df_2011_grouped_subsampled.matrix = df_2011_grouped_subsampled.matrix[,common_col_names]
```

```{r, eval = bool_execute_heavy_chunks}
# make cv folds

set.seed(123)

month.cv.k4.sets = suppressMessages(MakeMonthCvSets(my_df = df_2010,
                       month_sets_ind = month_sets_ind$k4,
                       formula = FORMULA.YES.INTERACTIONS,
                       threshold = 10))

save(month.cv.k4.sets, file = month.cv.k4.sets.name)


# make cv folds adding the zero counts

month.zeros.cv.k4.sets = suppressMessages(MakeMonthCvSetsZeros(my_df = df_2010,
                                              zeros_df = joined_zero_counts_2010_df,
                                              month_sets_ind = month_sets_ind$k4,
                       formula = FORMULA.YES.INTERACTIONS.sparse,
                       threshold = 10))

save(month.zeros.cv.k4.sets, file = month.zeros.cv.k4.sets.name)
```



### Esplicative quantitative

IL dtaset presenta principalmente esplicative categoriali, benchè le due esplicative quantitative (MdAge) permettano la specificazione di diverse forme funzionali qui, per ragioni computazionali ci si limita ad assumere una relazione monotona lineare con la risposta.

### Modelli per risposta continua

Nell'impiego dei modelli con risposta continua (con errori gaussiani i.i.d) si è scelto di stimare il modello su una trasformazione logaritmica della risposta: "y = count / n_month_train" (per i dati senza introduzione di conteggi nulli) e calcolare l'errore di previsioni sulla trasformazione "count = exp(y) * n_month_test" rispetto al numero di conteggi osservati, in questo modo la previsione è sempre positiva.

### Modelli e procedure considerati

I modelli considerati sono modelli normali con penalizzazioni LASSO, Elasticnet, SCAD ed MCP e modelli Poisson con penalizzazioni LASSO ed Elasticnet. Per per tutti i modelli si seleziona il parametro (eventualmente vettoriale) di regolazione che minimizza l'errore di convalida. Per i metodi per cui il parametro di regolarizzazione ha dimensione 2 si definisce una griglia di valori (di cui si riporta il grafico delle curve di livello dell'errore).
Per i metodi SCAD e MCP, poichè "ncvreg" presenta dei problemi computazionali dovute alle dimensioni del dataset è impiegata la libreria "picasso" che però non fornisce indicazioni rispetto alle regioni non convesse.


```{r, eval = bool_execute_heavy_chunks}
models_summary$lasso <- Lasso_CV(month.cv.k4.sets,
                                        my.lambda.vals = exp(seq(-20, 2, 0.1)) %>% sort(decreasing = T))
```


```{r, warning = FALSE, eval = bool_execute_heavy_chunks}
models_summary$scad = NonConvex_Cv(cv.sets = month.cv.k4.sets,
                                             my.lambda.vals = exp(seq(-15, 1, 0.2)) %>% sort(decreasing = TRUE),
                                             my.gamma.vals = seq(2+1e-05, 20, length = 10),
                                         my.penalty = "scad")

# backup to save key model info
save(models_summary, file = file_save_name)

```


```{r, warning = FALSE, eval = bool_execute_heavy_chunks}
models_summary$mcp = NonConvex_Cv(cv.sets = month.cv.k4.sets,
                                             my.lambda.vals = exp(seq(-15, 1, 0.2)) %>% sort(decreasing = TRUE),
                                             my.gamma.vals = seq(1+1e-05, 20, length = 10),
                                         my.penalty = "mcp")

# backup to save key model info
save(models_summary, file = file_save_name)
```

```{r, eval = bool_execute_heavy_chunks}

models_summary$elasticnet = Elastic_Cv(cv.sets = month.cv.k4.sets,
                                             my.lambda.vals = exp(seq(-20, 2, 0.3)) %>% sort(decreasing = TRUE),
                                             my.alpha.vals = seq(1e-5, 1 - 1e-5, length = 10))

# backup to save key model info
save(models_summary, file = file_save_name)
```



```{r}
# Known convergence difficult, see help here. https://cran.r-project.org/web/packages/glmnet/vignettes/glmnetFamily.pdf
glmnet.control(mxitnr = 50) # increase maximum no. of IRLS iterations allowed
```


```{r, eval = bool_execute_heavy_chunks, warning=FALSE}
models_summary$lasso.poi = Lasso_Offset_CV(cv.sets = month.cv.k4.sets,
                                          my.lambda.vals = exp(seq(-15, 3, 0.1)) %>% sort(decreasing = TRUE),
                                          my.family = poisson())

# backup to save key model info
save(models_summary, file = file_save_name)
```

```{r, eval = bool_execute_heavy_chunks, warning=FALSE}
models_summary$lasso.poi.zeros = Lasso_Offset_CV(cv.sets = month.zeros.cv.k4.sets,
                                          my.lambda.vals = exp(seq(-15, 3, 0.1)) %>% sort(decreasing = TRUE),
                                          my.family = poisson())

# backup to save key model info
save(models_summary, file = file_save_name)
```


```{r, warning=FALSE, eval = bool_execute_heavy_chunks}
models_summary$elasticnet.poi = Elastic_Offset_Cv(cv.sets = month.cv.k4.sets,
                                                        my.lambda.vals = exp(seq(-10, 2, 0.2)) %>% sort(decreasing = TRUE),
                                                        my.alpha.vals = seq(1e-5, 1 - 1e-5, length = 10),
                                                        my.family = poisson())

save(models_summary, file = file_save_name)
```



```{r, warning=FALSE, eval = bool_execute_heavy_chunks}
models_summary$elasticnet.poi.zeros = Elastic_Offset_Cv(cv.sets = month.zeros.cv.k4.sets,
                                                        my.lambda.vals = exp(seq(-10, 2, 0.2)) %>% sort(decreasing = TRUE),
                                                        my.alpha.vals = seq(1e-5, 1 - 1e-5, length = 10),
                                                        my.family = poisson())

# backup to save key model info
save(models_summary, file = file_save_name)
```


Per il modello normale il $\lambda$ minimo è molto vicino a zero (poichè la soluzione è sul bordo si dovrebbe provare a diminuire ulteriormente $\lambda$, ma già così i coefficienti sono quasi uguali alle stime non penalizzate).
Per il modello Poisson il $\lambda$ selezionato è maggiore. (Figura 
\@ref(fig:cv-err-lasso-linear-poi))

```{r cv-err-lasso-linear-poi, fig.show='hold', out.width = OUT.WIDTH, out.height= OUT.HEIGHT, fig.cap="Grafici dell'errore di convalida incrociata in funzione del parametro di regolazione per LASSO per moodelli lineare e Poisson"}
par(mfrow = c(1,2))

PlotOneDim(x = log(models_summary$lasso$lambda),
           y = models_summary$lasso$cv.err.matr$cv.err,
           se = models_summary$lasso$cv.err.matr$cv.se,
           x.min = log(models_summary$lasso$lmin),
           x.1se = log(models_summary$lasso$l1se),
           xlab = "log lambda",
           ylab = "CV error",
           main = "LASSO  CV error",
          min.leg = "lambda min",
           onese.leg = "lambda 1se")

PlotOneDim(x = log(models_summary$lasso.poi$lambda),
           y = models_summary$lasso.poi$cv.err.matr$cv.err,
           se = models_summary$lasso.poi$cv.err.matr$cv.se,
           x.min = log(models_summary$lasso.poi$lmin),
           x.1se = log(models_summary$lasso.poi$l1se),
           xlab = "log lambda",
           ylab = "CV error",
           main = "LASSO Poisson  CV error",
          min.leg = "lambda min",
           onese.leg = "lambda 1se")
```


Per il modello continuo Elasticnet individua un $\alpha$ intermedio tra Ridge e LASSO, ma come sopra il $\lambda$ è prossimo a zero (considerazioni uguali a sopra), nel modello Poisson invece è selezionata una Ridge con $\lambda$ non prossimo a zero. (Figura \@ref(fig:fig-cv-err-elastic-linear-poi))

```{r fig-cv-err-elastic-linear-poi, fig.show='hold', out.width = OUT.WIDTH, out.height= OUT.HEIGHT,fig.cap="Curve di livello dell'errore di convalida incrociata in funzione dei parametri di regolazione per Elasticnet dei modelli lineare e Poisson"}
par(mfrow = c(1,2))

TwoParErrPlot(model_list = models_summary$elasticnet,
              row_par_name = "lambda",
              col_par_name = "alpha",
              cv_err_matr_name = "cv.err.matr",
              row_par_min_name = "lmin",
              col_par_min_name = "amin",
              my.main = "Elasticnet  Cv error contour",
              my.xlab = "log lambda",
              my.ylab = "alpha")

TwoParErrPlot(model_list = models_summary$elasticnet.poi,
              row_par_name = "lambda",
              col_par_name = "alpha",
              cv_err_matr_name = "cv.err.matr",
              row_par_min_name = "lmin",
              col_par_min_name = "amin",
              my.main = "Elasticnet Poisson  Cv error contour",
              my.xlab = "log lambda",
              my.ylab = "alpha")

par(mfrow = c(1,1))
```


Sia per SCAD che per MCP il $\lambda$ selezionato è prossimo a zero, provando ad aumentare ulteriormente $\gamma$ e diminuire $\lambda$ la soluzione sostanzialmente non cambia. (Figura \@ref(fig:fig-cv-err-scad-mcp))
```{r fig-cv-err-scad-mcp, fig.show='hold', out.width = OUT.WIDTH, out.height= OUT.HEIGHT,fig.cap="Curve di livello dell'errore di convalida incrociata in funzione dei parametri di regolazione per SCAD ed MCP del modello lineare"}

par(mfrow = c(1,2))

TwoParErrPlot(model_list = models_summary$mcp,
              row_par_name = "lambda",
              col_par_name = "gamma",
              cv_err_matr_name = "cv.err.matr",
              row_par_min_name = "lmin",
              col_par_min_name = "gmin",
              my.main = "MCP  Cv error contour",
              my.xlab = "log lambda",
              my.ylab = "gamma")

TwoParErrPlot(model_list = models_summary$scad,
              row_par_name = "lambda",
              col_par_name = "gamma",
              cv_err_matr_name = "cv.err.matr",
              row_par_min_name = "lmin",
              col_par_min_name = "gmin",
              my.main = "SCAD  Cv error contour",
              my.xlab = "log lambda",
              my.ylab = "gamma")

par(mfrow = c(1,1))
```


Per i modelli di Poisson adattati con conteggi nulli i $\lambda$ ottimi tendono al metodo non penalizzato; nel caso di Elasticnet è selezionata una ridge (Figura \@ref(fig:fig-cv-err-zeros-poi)).
```{r fig-cv-err-zeros-poi, fig.show='hold', out.width = OUT.WIDTH, out.height= OUT.HEIGHT,fig.cap="Grafici dell'errore di convalida incrociata in funzione dei parametri di regolazione per LASSO ed Elasticnet per modelli Poisson per dati con aggiunta di zeri"}
par(mfrow = c(1,2))

PlotOneDim(x = log(models_summary$lasso.poi.zeros$lambda),
           y = models_summary$lasso.poi.zeros$cv.err.matr$cv.err,
           se = models_summary$lasso.poi.zeros$cv.err.matr$cv.se,
           x.min = log(models_summary$lasso$lmin),
           x.1se = log(models_summary$lasso$l1se),
           xlab = "log lambda",
           ylab = "CV error",
           main = "LASSO Poi zeros  CV error",
          min.leg = "lambda min",
           onese.leg = "lambda 1se")

TwoParErrPlot(model_list = models_summary$elasticnet.poi.zeros,
              row_par_name = "lambda",
              col_par_name = "alpha",
              cv_err_matr_name = "cv.err.matr",
              row_par_min_name = "lmin",
              col_par_min_name = "amin",
              my.main = "Elasticnet Poisson zeros  Cv error contour",
              my.xlab = "log lambda",
              my.ylab = "alpha")


```



```{r}
# backup to save key model info
save(models_summary, file = file_save_name)
```


Per confontare modelli per risposta continua e discreta nelle previsioni sui dati 2011 si approssimano le previsioni continue al primo intero

```{r, results='hide' ,eval = bool_execute_heavy_chunks, warning=FALSE}

# LASSO ---------------------
temp.fit = glmnet(x = df_2010_grouped_subsampled.matrix,
                  y = log(df_2010_grouped_subsampled$count) -log(12),
                  lambda = models_summary$lasso$lmin)

models_summary$lasso$beta = temp.fit$beta
models_summary$lasso$test_error = RMSEfun(df_2011_grouped_subsampled$count, 
                                          round(exp(predict(temp.fit, newx = df_2011_grouped_subsampled.matrix) + log(12))))

temp.fit = glmnet(x = df_2010_grouped_subsampled.matrix,
                  y = log(df_2010_grouped_subsampled$count) -log(12),
                  lambda = models_summary$lasso$l1se)

models_summary$lasso$beta1se = temp.fit$beta
models_summary$lasso$test_error1se = RMSEfun(df_2011_grouped_subsampled$count, 
                                          round(exp(predict(temp.fit, newx = df_2011_grouped_subsampled.matrix) + log(12))))

# Elasticnet ---------------------
temp.fit = glmnet(x = df_2010_grouped_subsampled.matrix,
                  y = log(df_2010_grouped_subsampled$count) -log(12),
                  alpha = models_summary$elasticnet$amin,
                  lambda = models_summary$elasticnet$lmin)

models_summary$elasticnet$beta = temp.fit$beta
models_summary$elasticnet$test_error = RMSEfun(df_2011_grouped_subsampled$count, 
                                          round(exp(predict(temp.fit, newx = df_2011_grouped_subsampled.matrix) + log(12))))


# SCAD ---------------------
temp.fit = picasso(X = df_2010_grouped_subsampled.matrix,
                  Y = log(df_2010_grouped_subsampled$count) -log(12),
                  gamma = models_summary$scad$gmin,
                  lambda = models_summary$scad$lmin,
                  method = "scad")

temp.lind = which(models_summary$scad$lambda == models_summary$scad$lmin)

models_summary$scad$beta = temp.fit$beta
models_summary$scad$test_error = RMSEfun(df_2011_grouped_subsampled$count, 
                                          round(exp(my.predict.gaussian(temp.fit, newdata = df_2011_grouped_subsampled.matrix,
                                                               lambda.idx = 1) +
                                                log(12))))

# MCP ----------------------
temp.fit = picasso(X = df_2010_grouped_subsampled.matrix,
                  Y = log(df_2010_grouped_subsampled$count) -log(12),
                  gamma = models_summary$mcp$gmin,
                  lambda = models_summary$mcp$lmin,
                  method = "mcp")

temp.lind = which(models_summary$mcp$lambda == models_summary$mcp$lmin)

models_summary$mcp$beta = temp.fit$beta
models_summary$mcp$test_error = RMSEfun(df_2011_grouped_subsampled$count, 
                                          round(exp(my.predict.gaussian(temp.fit, newdata = df_2011_grouped_subsampled.matrix,
                                                               lambda.idx = 1) +
                                                log(12))))


# LASSO Poisson ---------------------
temp.fit = glmnet(x = df_2010_grouped_subsampled.matrix,
                  y = df_2010_grouped_subsampled$count,
                  offset = rep(log(12), nrow(df_2010_grouped_subsampled.matrix)),
                  lambda = models_summary$lasso.poi$lmin,
                  family = poisson())

models_summary$lasso.poi$beta = temp.fit$beta
models_summary$lasso.poi$test_error = RMSEfun(df_2011_grouped_subsampled$count, 
                                          predict(temp.fit,
                                                  newx = df_2011_grouped_subsampled.matrix,
                                                  newoffset = rep(log(12), nrow(df_2011_grouped_subsampled.matrix)),
                                                  type = "response"))

temp.fit = glmnet(x = df_2010_grouped_subsampled.matrix,
                  y = df_2010_grouped_subsampled$count,
                  offset = rep(log(12), nrow(df_2010_grouped_subsampled.matrix)),
                  lambda = models_summary$lasso.poi$l1se,
                  family = poisson())

models_summary$lasso.poi$beta1se = temp.fit$beta
models_summary$lasso.poi$test_error1se = RMSEfun(df_2011_grouped_subsampled$count, 
                                          predict(temp.fit,
                                                  newx = df_2011_grouped_subsampled.matrix,
                                                  newoffset = rep(log(12), nrow(df_2011_grouped_subsampled.matrix),
                                                  type = "response")))

# LASSO poisson zeros
temp.fit = glmnet(x = df_2010_grouped_subsampled.matrix,
                  y = df_2010_grouped_subsampled$count,
                  offset = rep(log(12), nrow(df_2010_grouped_subsampled.matrix)),
                  lambda = models_summary$lasso.poi.zeros$lmin,
                  family = poisson())

models_summary$lasso.poi.zeros$beta = temp.fit$beta
models_summary$lasso.poi.zeros$test_error = RMSEfun(df_2011_grouped_subsampled$count, 
                                          predict(temp.fit,
                                                  newx = df_2011_grouped_subsampled.matrix,
                                                  newoffset = rep(log(12), nrow(df_2011_grouped_subsampled.matrix)),
                                                  type = "response"))


temp.fit = glmnet(x = df_2010_grouped_subsampled.matrix,
                  y = df_2010_grouped_subsampled$count,
                  offset = rep(log(12), nrow(df_2010_grouped_subsampled.matrix)),
                  lambda = models_summary$lasso.poi.zeros$l1se,
                  family = poisson())

models_summary$lasso.poi.zeros$beta1se = temp.fit$beta
models_summary$lasso.poi.zeros$test_error_1se = RMSEfun(df_2011_grouped_subsampled$count, 
                                          predict(temp.fit,
                                                  newx = df_2011_grouped_subsampled.matrix,
                                                  newoffset = rep(log(12), nrow(df_2011_grouped_subsampled.matrix)),
                                                  type = "response"))


# Elasticnet Poisson ---------------------
temp.fit = glmnet(x = df_2010_grouped_subsampled.matrix,
                  y = df_2010_grouped_subsampled$count,
                  offset = rep(log(12), nrow(df_2010_grouped_subsampled.matrix)),
                  alpha = models_summary$elasticnet.poi$amin,
                  lambda = models_summary$elasticnet.poi$lmin,
                  family = poisson())

models_summary$elasticnet.poi$beta = temp.fit$beta
models_summary$elasticnet.poi$test_error = RMSEfun(df_2011_grouped_subsampled$count, 
                                          predict(temp.fit,
                                                  newx = df_2011_grouped_subsampled.matrix,
                                                  newoffset = rep(log(12), nrow(df_2011_grouped_subsampled.matrix),
                                                  type = "response")))


# LASSO elasticnet zeros

temp.fit = glmnet(x = df_2010_grouped_subsampled.matrix,
                  y = df_2010_grouped_subsampled$count,
                  offset = rep(log(12), nrow(df_2010_grouped_subsampled.matrix)),
                  alpha = models_summary$elasticnet.poi.zeros$amin,
                  lambda = models_summary$elasticnet.poi.zeros$lmin,
                  family = poisson())

models_summary$elasticnet.poi.zeros$beta = temp.fit$beta
models_summary$elasticnet.poi.zeros$test_error = RMSEfun(df_2011_grouped_subsampled$count, 
                                          predict(temp.fit,
                                                  newx = df_2011_grouped_subsampled.matrix,
                                                  newoffset = rep(log(12), nrow(df_2011_grouped_subsampled.matrix),
                                                  type = "response")))

# backup to save key model info
save(models_summary, file = file_save_name)

```



```{r, fig.show='hold', out.width = OUT.WIDTH.1d, out.height= OUT.HEIGHT.1d, warning=FALSE}

# Benchè con la libreria impiegata non siano fornite informazione precise sulla regione delle stime si può comunque provare a valutare la stabilità graficamente.
# 
# par(mfrow = c(1,2))
# 
# # SCAD ---------------------
# temp.fit = picasso(X = df_2010_grouped_subsampled.matrix,
#                   Y = log(df_2010_grouped_subsampled$count) -rep(log(12), nrow(df_2010_grouped_subsampled.matrix)),
#                   gamma = models_summary$scad$gmin,
#                   lambda = models_summary$scad$lambda,
#                   method = "scad")
# 
# temp.fit = ncvreg(X = as.matrix(df_2010_grouped_subsampled.matrix),
#                   y = log(df_2010_grouped_subsampled$count) -rep(log(12), nrow(df_2010_grouped_subsampled.matrix)),
#                   gamma = models_summary$scad$gmin,
#                   lambda = models_summary$scad$lambda,
#                   penalty = "SCAD")
# 
# plot(log(temp.fit$lambda), t(temp.fit$beta),
#              type = "l", main = "SCAD Regularization Path",
#     xlab = "Regularization Parameter", ylab = "Coefficient")
# abline(v = log(models_summary$scad$lmin))
# 
# # MCP ----------------------
# temp.fit = picasso(X = df_2010_grouped_subsampled.matrix,
#                   Y = log(df_2010_grouped_subsampled$count) -rep(log(12), nrow(df_2010_grouped_subsampled.matrix)),
#                   gamma = models_summary$mcp$gmin,
#                   lambda = models_summary$mcp$lambda,
#                   method = "mcp")
# 
# matplot(log(temp.fit$lambda), t(temp.fit$beta),
#         type = "l", main = "MCP Regularization Path",
#     xlab = "Regularization Parameter", ylab = "Coefficient")
# abline(v = log(models_summary$mcp$lmin))
# 
# par(mfrow = c(1,1))
```

```{r, results='hide'}
suppressMessages(rm(temp.fit))
suppressMessages(gc())
```




### Modelli migliori

Si riportano gli errori di previsione sui dati del 2011 (senza zeri) dei vari modelli migliori stimati sui dati completi 2010 (senza zeri). La milgior previsione si ha per il modello Poisson con penalità LASSO (selezionato sui dati con gli zeri) per $\lambda$ a errore a un errore standard, mentre il peggiore è sempre il modello di Poisson ma con penalità Elasticnet.
```{r}
models.errors = data.frame(model = c("lasso",
                                     "lasso.1se",
                                     "elasticnet",
                                     "scad",
                                     "mcp",
                                     "poisson_lasso",
                                     "poisson_lasso1se",
                                     "poisson_elasticnet",
                                     "poisson_lasso.zeros",
                                     "poisson_lasso.zeros.1se",
                                     "poisson_elasticnet_zeros"),
                           test_error = c(models_summary$lasso$test_error,
                                          models_summary$lasso$test_error1se,
                                          models_summary$elasticnet$test_error,
                                          models_summary$scad$test_error,
                                          models_summary$mcp$test_error,
                                          models_summary$lasso.poi$test_error,
                                          models_summary$lasso.poi$test_error1se,
                                          models_summary$elasticnet.poi$test_error,
                                          models_summary$lasso.poi.zeros$test_error,
                                          models_summary$lasso.poi.zeros$test_error_1se,
                                          models_summary$elasticnet.poi.zeros$test_error))

models.errors
```


I grafici dei coefficienti stimati confermano, per LASSO ed Elasticnet non avviene selezione delle variabili.
Le stime non sono sparse nemmeno con il criterio dell'errore a un errore standard.
Anche per SCAD ed MCP non avviene selezione di variabili: le stime (non riportate) sono quasi uguali a quelle LASSO ed Elasticnet, non si reputa quindi necessario controllare l'eventuale regione non convessa delle stime (Figura \@ref(fig:fig-beta-lasso-elastic-linear-poi)).
```{r fig-beta-lasso-elastic-linear-poi,  fig.show='hold', out.width = OUT.WIDTH.1d, out.height= OUT.HEIGHT.1d,fig.cap="Grafici dei coefficienti stimati sui dati 2010 dei modelli selezionati precedentemente per LASSO ed Elasticnet per modelli lineare e Poisson"}

par(mfrow = c(1,2))
plot(models_summary$lasso$beta, pch = 16,
     main = "LASSO & Elasticnet",
     xlab = "beta index", ylab = "beta",
     ylim = range(c(as.vector(models_summary$lasso$beta),as.vector(models_summary$elasticnet$beta))))
points(models_summary$elasticnet$beta, col = "red")

legend("bottomright",
       legend = c("LASSO", "Elasticnet"),
       col = c(1,2),
       lty = 1,
       bty = "n")

plot(models_summary$lasso.poi$beta, pch = 16,
      main = "Poisson LASSO & Elasticnet",
     xlab = "beta index", ylab = "beta",
     ylim = range(c(as.vector(models_summary$lasso.poi$beta), as.vector(models_summary$elasticnet.poi$beta))))
points(models_summary$elasticnet.poi$beta, col = "red")

legend("bottomright",
       legend = c("LASSO", "Elasticnet"),
       col = c(1,2),
       lty = 1,
       bty = "n")
```


```{r}
# plot(models_summary$scad$beta, pch = 16,
#       main = "SCAD & MCP beta estimates",
#      xlab = "beta index", ylab = "beta",
#      ylim = range(c(as.vector(models_summary$scad$beta), as.vector(models_summary$mcp$beta))))
# points(models_summary$mcp$beta, col = "red")
# 
# legend("bottomright",
#        legend = c("SCAD", "MCP"),
#        col = c(1,2),
#        lty = 1,
#        bty = "n")
```


I modelli Poisson adattati considerando gli zeri presentano una maggiore selezione di variabili rispetto ai precedenti (Figura \@ref(fig:fig-beta-zeros-lasso-poi)).
```{r fig-beta-zeros-lasso-poi,  fig.show='hold', out.width = OUT.WIDTH.1d, out.height= OUT.HEIGHT.1d,fig.cap="Grafici dei coefficienti stimati sui dati 2010 dei modelli Poisson (LASSO) selezionati precedentemente sui dati con aggiunta di zeri"}

par(mfrow = c(1,1))
plot(models_summary$lasso.poi.zeros$beta, pch = 16,
     main = "Poisson LASSO zeros min & 1se ",
     xlab = "beta index", ylab = "beta",
     ylim = range(c(as.vector(models_summary$lasso.poi.zeros$beta),as.vector(models_summary$lasso.poi.zeros$beta1se))))
points(models_summary$lasso.poi.zeros$beta1se, col = "red")

legend("bottomright",
       legend = c("min", "1se"),
       col = c(1,2),
       lty = 1,
       bty = "n")
```


La tabella sottostante contiene per ciascun modello il rapporto tra il numero di elementi non nulli e il numero di elementi totali del vettore dei coefficienti: il modello Poisson con penalizzazione LASSO (criterio a un errore standard) e impiegando gli zeri è quello con il rapporto minore, questo modello è dunque l'oggetto delle successive analisi.

E' interessante notare come il modello con la migliore previsione sui dati 2011 sia quello con penalizzazione LASSO e non Elastic, come ci si sarebbe potuti invece aspettare data la natura di correlazione delle esplicative data dall'introduzione dei termini di interazione.
Poichè le stime LASSO per esplicative correlate non sono stabili le conclusioni inferenziali ed intepretative devono essere prese con cautela.

Si ricorda che per GLM di Poisson con legame canonico, in assenza di interazioni, l'aumento unitario di una variabile fissate tutte le altre induce una modifica moltiplicativa nel parametro della media pari all'esponenziale del coefficiente associato alla variabile. Nel caso considerato il parametro è il numero di arresti medi mensili (poichè si è introdotto l'offset). Sono presenti delle ulteriori difficoltà interpretative dei coefficienti dovuti alla standardizzazione delle variabili e al sottocampionamento che di fatto sottostima il numero di conteggi nulli o bassi. In questa analisi si è inoltre più interessati alle variabili associate a un incremento degli arresti più che a una loro diminuizione.


```{r}

SparsityRatio = function(vec){
  mean(vec != 0)
}

models.zero.beta = data.frame(model = c("lasso",
                                     "lasso.1se",
                                     "elasticnet",
                                     "scad",
                                     "mcp",
                                     "poisson_lasso",
                                     "poisson_lasso1se",
                                     "poisson_elasticnet",
                                     "poisson_lasso.zeros",
                                     "poisson_lasso.zeros.1se",
                                     "poisson_elasticnet_zeros"),
                           not_null_ratio = c(models_summary$lasso$beta %>% SparsityRatio(),
                                          models_summary$lasso$beta1se %>% SparsityRatio(),
                                          models_summary$elasticnet$beta %>% SparsityRatio(),
                                          models_summary$scad$beta %>% SparsityRatio(),
                                          models_summary$mcp$beta %>% SparsityRatio(),
                                          models_summary$lasso.poi$beta %>% SparsityRatio(),
                                          models_summary$lasso.poi$beta1se %>% SparsityRatio(),
                                          models_summary$elasticnet.poi$beta %>% SparsityRatio(),
                                          models_summary$lasso.poi.zeros$beta %>% SparsityRatio(),
                                          models_summary$lasso.poi.zeros$beta1se %>% SparsityRatio(),
                                          models_summary$elasticnet.poi.zeros$beta %>% SparsityRatio()))

models.zero.beta
```



E' riportata la mappa (Figura \@ref(fig:fig-beta-lasso-zeros-nta2020)) degli NTA colorati in base al valore del corrispettivo coefficiente (marginale) (le zone grigie corrispondono a zone non presenti nei dati, e quindi coefficienti non stimati),per alcuni NTA sono presenti i nomi dei corrispettivi codici, questi sono in corrispondenza dei coefficienti più grandi relativi a termini di interazione in cui sono presenti tali NTA (vedasi sotto).

```{r, results='hide'}
geo_data = st_read("../../data/coordinates_maps/nta.geojson")
```


```{r, warning=FALSE, message=FALSE}

beta_names = colnames(df_2010_grouped_subsampled.matrix)

# Filter the data for specific NTA2020 values

specific_ntas <- sub(".*NTA2020([A-Z0-9]+).*", "\\1", models_summary$lasso.poi.zeros$beta_big$names)
filtered_data <- geo_data %>% filter(NTA2020 %in% specific_ntas)

# Extract coordinates from the sf object
filtered_data_coords <- st_coordinates(filtered_data)


nta_columns <- grep("^NTA2020", beta_names)



nta_beta_matrix = data.frame(NTA2020 = sub("NTA2020", "",beta_names[nta_columns]),
                        beta = models_summary$lasso.poi.zeros$beta[nta_columns])

# Merge the geo_data with nta_values
geo_data <- merge(geo_data, nta_beta_matrix, by.x = "NTA2020", by.y = "NTA2020", all.x = TRUE)

```

```{r fig-beta-lasso-zeros-nta2020, warning=FALSE,fig.show='hold', out.width = OUT.WIDTH.1d, out.height= OUT.HEIGHT.1d,fig.cap="Grafici dei coefficienti stimati sui dati 2010 del modello Poisson (LASSO) selezionato con criterio a un errore standard sui dati con aggiunta di zeri relativi a ciascun NTA"}
# Create the map plot with the viridis palette
map_with_viridis <- ggplot(data = geo_data) +
  geom_sf(aes(fill = beta)) +
  scale_fill_viridis(option = "viridis", name = "Values", na.value = "grey50") +
  labs(title = "NTA Poisson LASSO 1se zeros beta")

# Add NTA names directly on the regions
map_with_viridis <- map_with_viridis +
  geom_sf_text(data = filtered_data, aes(label = NTA2020), size = 3, color = "white")

print(map_with_viridis)
```
Si riportano anche le tabelle dei cofficienti per le variabili qualitative (marginali).

```{r}
# Select column names containing only non interaction
LAW_CAT_CD_indexes = grep("LAW_CAT_CD(?!.*NTA2020)", beta_names, perl = TRUE)
LAW_CAT_CD_betas = data.frame(LAW_CAT_CD = sub("LAW_CAT_CD", "", beta_names[LAW_CAT_CD_indexes]),
                              beta = models_summary$lasso.poi.zeros$beta[LAW_CAT_CD_indexes])

KY_CD_indexes = grep("KY_CD(?!.*NTA2020)", beta_names, perl = TRUE)
KY_CD_betas = data.frame(KY_CD = sub("KY_CD", "", beta_names[KY_CD_indexes]),
                              beta = models_summary$lasso.poi.zeros$beta[KY_CD_indexes])

PERP_SEX_indexes = grep("PERP_SEX(?!.*NTA2020)", beta_names, perl = TRUE)
PERP_SEX_betas = data.frame(PERP_SEX = sub("PERP_SEX", "", beta_names[PERP_SEX_indexes]),
                              beta = models_summary$lasso.poi.zeros$beta[PERP_SEX_indexes])

PERP_RACE_indexes = grep("PERP_RACE(?!.*NTA2020)", beta_names, perl = TRUE)
PERP_RACE_betas = data.frame(PERP_RACE = sub("PERP_RACE", "", beta_names[PERP_RACE_indexes]),
                              beta = models_summary$lasso.poi.zeros$beta[PERP_RACE_indexes])

AGE_GROUP_indexes = grep("AGE_GROUP(?!.*NTA2020)", beta_names, perl = TRUE)
AGE_GROUP_betas = data.frame(AGE_GROUP = sub("AGE_GROUP", "", beta_names[AGE_GROUP_indexes]),
                              beta = models_summary$lasso.poi.zeros$beta[AGE_GROUP_indexes])

# also find the numerics
census_cols <- c("Pop1", "MdAge", "MaleP", "Hsp1P", "BNHP", "OthNHP", "WNHP", "ANHP", "MIncome")

census_betas = data.frame(var = census_cols,
                          beta = models_summary$lasso.poi.zeros$beta[match(census_cols, beta_names)])
```


Tutti i gruppi di età presentao coefficienti positivi ad eccezione della fascia più anziana.
```{r}
AGE_GROUP_betas
```

La percentuale di maschi è associata ad un coefficiente positivo.
```{r}
PERP_SEX_betas
```

I coefficienti positivi sono relativi a razza bianca, ispanica e nera.
```{r}
PERP_RACE_betas
```


I coefficienti relativi alle variabili del censo sono relativamente piccoli rispetto a quelli per le altre variabili.
```{r}
census_betas
```


Per le macro categorie di reato solo l'omicidio presenta una coefficiente positivo.
```{r}
LAW_CAT_CD_betas
```

Si riporta il grafico dei coefficienti per le categorie più granulari di arresto (Figura \@ref(fig:fig-beta-lasso-zeros-ky-cd)).
```{r fig-beta-lasso-zeros-ky-cd, fig.show='hold', out.width = OUT.WIDTH.1d, out.height= OUT.HEIGHT.1d,fig.cap="Grafici dei coefficienti stimati sui dati 2010 del modello Poisson (LASSO) selezionato con criterio a un errore standard sui dati con aggiunta di zeri relativi alle categorie granulare di arresto KYCD"}
dotchart(KY_CD_betas$beta[order(KY_CD_betas$beta)],
         labels = KY_CD_betas$KY_CD[order(KY_CD_betas$beta)],
         cex = 0.7, pch = 16, main = "KY_CD beta")
```


Poichè si è più interessati ai termini correlati positivamente con il numero di arresti si riportano di seguito i 20 coefficienti più grandi del modello Poisson più sparso descritto sopra.


Il termine più grande e gli altri due che coinvolgono l'interazioe tra NTA e la fascia d'età massima compensano il valore negativo del coefficiente marginale per quella fascia d'età per quelle specifiche zone; un ragionamento analogo vale per i termini di interazione che comprendono la modalità "razza asiatica" (Figura \@ref(fig:fig-beta-lasso-zeros-interaction))

```{r fig-beta-lasso-zeros-interaction,fig.show='hold', out.width = OUT.WIDTH.1d, out.height= OUT.HEIGHT.1d,fig.cap="Grafici dei 20 più grandi coefficienti stimati sui dati 2010 del modello Poisson (LASSO) selezionato con criterio a un errore standard sui dati con aggiunta di zeri"}
models_summary$lasso.poi.zeros$beta_big_1se = PlotFirstCoefs(coef_vec = models_summary$lasso.poi.zeros$beta1se,
                  coef_names = beta_names,
                  first_n = 20,
                  my.main = "LASSO Poisson zeros 1se")
```











